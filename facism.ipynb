{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python\\\n",
    "# import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash ./download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pysparkexample\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filename):\n",
    "    img_BGR = cv2.imread(filename)\n",
    "    img_BGR = img_BGR.astype(np.uint8)\n",
    "    return img_BGR\n",
    "\n",
    "\n",
    "def grayscale(img_BGR):\n",
    "    img_grayscale = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    return img_grayscale\n",
    "\n",
    "\n",
    "def process(filename, faceCascade, scale_factor=1.1, min_Neighbors=5, min_Size=(30,30)):\n",
    "    img_BGR = read_image(filename)\n",
    "    img_grayscale = grayscale(img_BGR)\n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(img_grayscale, scaleFactor=scale_factor, minNeighbors=min_Neighbors, minSize=min_Size)\n",
    "    return faces\n",
    "\n",
    "def find_these_files(directory):\n",
    "    roots = set()\n",
    "    dirs = set()\n",
    "    files = set()\n",
    "    for(root_folder, directory_list, file_list) in os.walk(directory):\n",
    "        roots.add(root_folder)\n",
    "        for directory in directory_list:\n",
    "            dirs.add(directory)\n",
    "        for file in file_list:\n",
    "            abspath = os.path.join(root_folder, file)\n",
    "            files.add(abspath)\n",
    "    return list(files)\n",
    "\n",
    "\n",
    "def test_haar_cascades(df, cascades):\n",
    "    results = pd.DataFrame()\n",
    "    i = 0\n",
    "    j = 0\n",
    "    t0 = time()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for cascade in cascades:\n",
    "        i = i + 1\n",
    "        j = 0\n",
    "        print(\"-----------------------------------------\")\n",
    "        print(i, \" of \", len(cascades), \" in outer loop.\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        cascade_classifier = cv2.CascadeClassifier(cascade)\n",
    "        for path in df['Path']:\n",
    "            j = j + 1\n",
    "            if j == 1 or j % 10 == 0:\n",
    "                print(\"\\t\", j, \" of \", len(df['Path']), \" in inner loop\")\n",
    "                pass\n",
    "            try:\n",
    "                result = process(path, cascade_classifier)\n",
    "                result = len(result)\n",
    "                tmp = [result, cascade, path]\n",
    "                results.append(tmp)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    results = np.array(results)\n",
    "    results = pd.DataFrame(results)\n",
    "    results = results.rename(columns = {0: \"Faces\", \n",
    "                              1: \"Cascade\", \n",
    "                              2: \"Path\"})\n",
    "    print(\"\\t\", j, \" of \", len(df['Path']), \" in inner loop\")\n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "def find_faces(directory, cascade):\n",
    "    paths = find_these_files(directory)\n",
    "    files = find_these_files(\"lfw-subset/raw/\")\n",
    "    df = create_data_frame_lfw(files)\n",
    "#     df = pd.DataFrame({ \"Path\" : paths})\n",
    "    results = test_haar_cascades(df, [cascade])\n",
    "    return results\n",
    "\n",
    "def create_data_frame_lfw(files, delims = \"/.\"):\n",
    "    dataframe = []\n",
    "    for file in files:\n",
    "        fullpath = copy.deepcopy(file)\n",
    "        file = file.replace(\"../\", \"\") #drop relative path\n",
    "        for delim in delims:\n",
    "            file = file.replace(delim,\", \") # Change all delims to commas\n",
    "        file = file.replace(\" , \" ,\"\") # Drop extra commas\n",
    "        file = file.replace('\\'', \"\") # Drop back slashes\n",
    "        file = file.strip()\n",
    "        file = file.split(\",\") # Creates a list from the string\n",
    "        file.append(str(fullpath))\n",
    "        dataframe.append(file)\n",
    "        \n",
    "    dataframe = pd.DataFrame(dataframe, columns = [ \"Root\", \"Folder\", \"Identity\", \"File\", \"Type\", \"Path\"])\n",
    "#     dataframe = dataframe.drop(\"Blank\", axis = 1)\n",
    "    return(dataframe)\n",
    "\n",
    "def segment_otsu(image_grayscale, img_BGR):\n",
    "    threshold_value, threshold_image = cv2.threshold(image_grayscale, 0, 255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    threshold_image_binary = 1- threshold_image/255\n",
    "    threshold_image_binary = np.repeat(threshold_image_binary[:, :, np.newaxis], 3, axis=2)\n",
    "    img_face_only = np.multiply(threshold_image_binary, img_BGR)\n",
    "    img_face_only = img_face_only.astype(np.uint8)\n",
    "    return img_face_only\n",
    "\n",
    "def skin_tone_estimator(img_face_only, verbose = False):\n",
    "    img_HSV = cv2.cvtColor(img_face_only, cv2.COLOR_BGR2HSV)\n",
    "    img_YCrCb = cv2.cvtColor(img_face_only, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # aggregate skin pixels\n",
    "    blue = []\n",
    "    green = []\n",
    "    red = []\n",
    "\n",
    "    height, width, channels = img_face_only.shape\n",
    "\n",
    "    for i in range (height):\n",
    "        for j in range (width):\n",
    "            if((img_HSV.item(i, j, 0) <= 170) and (140 <= img_YCrCb.item(i, j, 1) <= 170) and (90 <= img_YCrCb.item(i, j, 2) <= 120)):\n",
    "                blue.append(img_face_only[i, j].item(0))\n",
    "                green.append(img_face_only[i, j].item(1))\n",
    "                red.append(img_face_only[i, j].item(2))\n",
    "            else:\n",
    "                img_face_only[i, j] = [0, 0, 0]\n",
    "\n",
    "    # determine mean skin tone estimate\n",
    "    skin_tone_estimate_BGR = [np.mean(blue), np.mean(green), np.mean(red)]\n",
    "    return skin_tone_estimate_BGR\n",
    "\n",
    "def skin_tone_process(filename, verbose = False):\n",
    "    img_BGR = read_image(filename)\n",
    "    try:\n",
    "        img_grayscale = grayscale(img_BGR)\n",
    "    except:\n",
    "        print(\"grayscale didn't work\")\n",
    "    try:\n",
    "        img_face_only = segment_otsu(img_grayscale, img_BGR)\n",
    "    except:\n",
    "        print(\"segment broken\")\n",
    "    try:\n",
    "        skin_tone_estimate_BGR = skin_tone_estimator(img_face_only, verbose)\n",
    "    except:\n",
    "        print(\"skin_tone_broken @ \", filename)\n",
    "    relative_luminance = .2126 * skin_tone_estimate_BGR[2] + .7152 * skin_tone_estimate_BGR[1] + .0722 * skin_tone_estimate_BGR[0]\n",
    "    return relative_luminance\n",
    "def luminance_iterator(paths, verbose = False):\n",
    "    lums = []\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        try:\n",
    "            lums.append(skin_tone_process(path))\n",
    "        except:\n",
    "            print(\"Numerical Error. Skipping this image.\")\n",
    "            lums.append(\"NaN\")\n",
    "        i = i + 1\n",
    "        if verbose == True and i % 1000 == 0:\n",
    "            print(round(i/len(paths)*100,1) , \"% Complete.\")\n",
    "    return lums\n",
    "\n",
    "def calculate_luminance(df): \n",
    "    paths = df['Path']\n",
    "    lums= luminance_iterator(paths, True)\n",
    "    df['Luminance'] = lums\n",
    "    return df\n",
    "def bin_luminance(df, no_bins = 7, bin_labels = [\"Least Reflective\", \"Much Less Reflective\", \n",
    "                                       \"Less Reflective\", \"Average Reflectivity\", \n",
    "                                       \"Somewhat More Reflective\", \"More Reflective\", \n",
    "                                       \"Most Reflective\"]):\n",
    "    labelled, bins = pd.cut(df.Luminance, no_bins, \n",
    "                              labels = bin_labels,\n",
    "                              retbins = True, \n",
    "                              precision = 0)\n",
    "    dummy = pd.get_dummies(labelled)\n",
    "    df = pd.concat([df, dummy], axis = 1)\n",
    "    return df, bin_labels\n",
    "\n",
    "def clean_and_save(df, file_location = 'dataset.csv', no_bins = 3, bin_labels = [\"Less Reflective\", \"Average Reflectivity\", \"More Reflective\"]):    \n",
    "    print(\"Saving \", file_location,)\n",
    "    df.dropna(axis = 'rows', how =  'any',  inplace = True)\n",
    "    df = df.loc[df.Luminance.notnull()]\n",
    "    df = df[df.Luminance != 'NA']\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 'columns')\n",
    "    try:\n",
    "        df = df.drop(['level_0', 'index'], 1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df = bin_pose(df, bin_labels)\n",
    "    except:\n",
    "        pass\n",
    "    df, clean_and_save = bin_luminance(df, no_bins, bin_labels)\n",
    "    df.to_csv(file_location)\n",
    "    return df, bin_labels\n",
    "\n",
    "\n",
    "def luminance(files):\n",
    "    files = find_these_files(\"lfw-subset/raw/\")\n",
    "    df = create_data_frame_lfw(files)\n",
    "    df = calculate_luminance(df)\n",
    "    df, bin_labels = clean_and_save(df, 'results.csv')\n",
    "    return df, bin_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving  results.csv\n",
      "-----------------------------------------\n",
      "1  of  1  in outer loop.\n",
      "-----------------------------------------\n",
      "\t 1  of  35  in inner loop\n",
      "\t 10  of  35  in inner loop\n",
      "\t 20  of  35  in inner loop\n",
      "\t 30  of  35  in inner loop\n",
      "\t 35  of  35  in inner loop\n",
      "Accuracy of Detector is 97.14 %\n",
      "Final Results Saved at results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Root</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Identity</th>\n",
       "      <th>File</th>\n",
       "      <th>Type</th>\n",
       "      <th>Path</th>\n",
       "      <th>Luminance</th>\n",
       "      <th>Less Reflective</th>\n",
       "      <th>Average Reflectivity</th>\n",
       "      <th>More Reflective</th>\n",
       "      <th>Faces</th>\n",
       "      <th>Cascade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lfw-subset</td>\n",
       "      <td>raw</td>\n",
       "      <td>Anna_Kournikova</td>\n",
       "      <td>Anna_Kournikova_0005</td>\n",
       "      <td>jpg</td>\n",
       "      <td>lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...</td>\n",
       "      <td>138.982913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>haarcascade_frontalface_default.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lfw-subset</td>\n",
       "      <td>raw</td>\n",
       "      <td>Anna_Kournikova</td>\n",
       "      <td>Anna_Kournikova_0003</td>\n",
       "      <td>jpg</td>\n",
       "      <td>lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...</td>\n",
       "      <td>139.480126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>haarcascade_frontalface_default.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lfw-subset</td>\n",
       "      <td>raw</td>\n",
       "      <td>Ann_Veneman</td>\n",
       "      <td>Ann_Veneman_0003</td>\n",
       "      <td>jpg</td>\n",
       "      <td>lfw-subset/raw/Ann_Veneman/Ann_Veneman_0003.jpg</td>\n",
       "      <td>150.848303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>haarcascade_frontalface_default.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lfw-subset</td>\n",
       "      <td>raw</td>\n",
       "      <td>Adrien_Brody</td>\n",
       "      <td>Adrien_Brody_0005</td>\n",
       "      <td>jpg</td>\n",
       "      <td>lfw-subset/raw/Adrien_Brody/Adrien_Brody_0005.jpg</td>\n",
       "      <td>146.151735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>haarcascade_frontalface_default.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lfw-subset</td>\n",
       "      <td>raw</td>\n",
       "      <td>Anna_Kournikova</td>\n",
       "      <td>Anna_Kournikova_0001</td>\n",
       "      <td>jpg</td>\n",
       "      <td>lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...</td>\n",
       "      <td>146.763826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>haarcascade_frontalface_default.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Root Folder          Identity                   File  Type  \\\n",
       "0  lfw-subset    raw   Anna_Kournikova   Anna_Kournikova_0005   jpg   \n",
       "1  lfw-subset    raw   Anna_Kournikova   Anna_Kournikova_0003   jpg   \n",
       "2  lfw-subset    raw       Ann_Veneman       Ann_Veneman_0003   jpg   \n",
       "3  lfw-subset    raw      Adrien_Brody      Adrien_Brody_0005   jpg   \n",
       "4  lfw-subset    raw   Anna_Kournikova   Anna_Kournikova_0001   jpg   \n",
       "\n",
       "                                                Path   Luminance  \\\n",
       "0  lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...  138.982913   \n",
       "1  lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...  139.480126   \n",
       "2    lfw-subset/raw/Ann_Veneman/Ann_Veneman_0003.jpg  150.848303   \n",
       "3  lfw-subset/raw/Adrien_Brody/Adrien_Brody_0005.jpg  146.151735   \n",
       "4  lfw-subset/raw/Anna_Kournikova/Anna_Kournikova...  146.763826   \n",
       "\n",
       "   Less Reflective  Average Reflectivity  More Reflective  Faces  \\\n",
       "0                1                     0                0      1   \n",
       "1                1                     0                0      1   \n",
       "2                1                     0                0      1   \n",
       "3                1                     0                0      1   \n",
       "4                1                     0                0      1   \n",
       "\n",
       "                               Cascade  \n",
       "0  haarcascade_frontalface_default.xml  \n",
       "1  haarcascade_frontalface_default.xml  \n",
       "2  haarcascade_frontalface_default.xml  \n",
       "3  haarcascade_frontalface_default.xml  \n",
       "4  haarcascade_frontalface_default.xml  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
